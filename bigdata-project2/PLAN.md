# MapReduce 实验方案

## 📋 实验概览

本实验需要使用 MapReduce 编程模型对优惠券使用数据进行分析，共包含 4 个任务。

---

## 🎯 任务分析与实现方案

### 任务一：商家优惠券使用情况统计

**目标**：统计每个商家的三种优惠券使用情况（线上/线下分开）

**数据分类规则**：
- **负样本**：领取优惠券但未使用 (`Date=null` && `Coupon_id != null`)
- **普通消费**：未领取优惠券直接消费 (`Date!=null` && `Coupon_id = null`)
- **正样本**：领取优惠券并使用 (`Date!=null` && `Coupon_id != null`)

**MapReduce 设计**：
- **Mapper**：
  - 输入：CSV 每一行
  - 输出：Key=`商家ID_类型(offline/online)`，Value=`样本类型(negative/normal/positive)`
  
- **Reducer**：
  - 输入：同一商家的所有样本类型
  - 输出：`商家ID TAB 负样本数 TAB 普通消费数 TAB 正样本数`

---

### 任务二：商家距离统计

**目标**：统计每个商家不同距离的活跃消费者人数

**数据处理**：
- 只处理 `ccf_offline_stage1_train.csv`
- 距离字段 `Distance` 可能为 `null`（需要单独统计）
- 距离范围：0-10（代表 0-5000米）

**MapReduce 设计**：
- **Mapper**：
  - 输入：CSV 每一行
  - 过滤：只统计有效记录（有消费行为的）
  - 输出：Key=`商家ID_距离值`，Value=`用户ID`
  
- **Reducer**：
  - 输入：同一商家同一距离的所有用户
  - 去重：统计不同用户数量
  - 输出：`商家ID TAB 距离0:人数,距离1:人数,...`

---

### 任务三：优惠券使用间隔统计

**目标**：计算高频优惠券的平均使用间隔

**计算逻辑**：
1. 统计每种优惠券的被使用次数
2. 筛选使用次数 > 总使用次数 1% 的优惠券
3. 计算这些优惠券从领取到使用的平均间隔天数
4. 按平均间隔排序

**MapReduce 设计（两轮）**：

**第一轮 - 统计使用次数**：
- Mapper：输出 Key=`Coupon_id`，Value=1（仅当 `Date!=null` 且 `Coupon_id != null`）
- Reducer：统计总次数

**第二轮 - 计算平均间隔**：
- Mapper：
  - 读取第一轮结果，过滤高频优惠券
  - 输出 Key=`Coupon_id`，Value=`间隔天数`（Date - Date_received）
- Reducer：计算平均值并排序

---

### 任务四：自定义影响因素分析

**建议分析方向**：

1. **折扣力度对使用率的影响**
   - 分析不同折扣率的优惠券使用情况
   - 对比直接折扣 vs 满减优惠的效果

2. **时间因素分析**
   - 周末 vs 工作日的优惠券使用率
   - 月初 vs 月末的消费行为差异

3. **距离因素深度分析**
   - 不同距离区间的优惠券使用率
   - 距离与使用间隔的关系

---

## 🛠️ 技术实现方案

### 方案选择

**推荐使用 Python Hadoop Streaming**：
- 使用 Python 编写 Mapper 和 Reducer
- 通过 Hadoop Streaming 接口运行
- 优点：开发简单、调试方便、适合数据分析

**备选方案**：
- Java MapReduce（性能更好，但开发复杂）
- Spark（更现代，但可能超出实验要求）

### 项目结构

```
bigdata-project2/
├── data/                      # 数据目录
│   ├── ccf_offline_stage1_train.csv
│   └── ccf_online_stage1_train.csv
├── src/                       # 源代码
│   ├── task1/
│   │   ├── mapper.py
│   │   └── reducer.py
│   ├── task2/
│   │   ├── mapper.py
│   │   └── reducer.py
│   ├── task3/
│   │   ├── mapper1.py
│   │   ├── reducer1.py
│   │   ├── mapper2.py
│   │   └── reducer2.py
│   └── task4/
│       ├── mapper.py
│       └── reducer.py
├── output/                    # 输出结果
│   ├── task1/
│   ├── task2/
│   ├── task3/
│   └── task4/
├── logs/                      # 运行日志
├── run.sh                     # 运行脚本
├── test_local.sh              # 本地测试脚本
└── 实验报告.md                # 实验报告
```

---

## ⚠️ 重要注意事项

### 1. 数据处理注意事项

- **NULL 值处理**：CSV 中的 `null` 是字符串，不是 Python 的 `None`
- **日期格式**：`20160101` 格式，需要转换为日期对象进行计算
- **编码问题**：确保使用 UTF-8 编码读取 CSV
- **头部跳过**：CSV 第一行是列名，需要跳过

### 2. MapReduce 编程注意事项

- **输入输出**：Mapper 从 `stdin` 读取，输出到 `stdout`；Reducer 同理
- **键值分隔**：使用 TAB（`\t`）分隔 Key 和 Value
- **排序保证**：Hadoop 自动按 Key 排序后传给 Reducer
- **组合器**：可选使用 Combiner 提高性能

### 3. 本地测试方法

在没有 Hadoop 环境时，可以使用管道模拟：

```bash
cat data.csv | python mapper.py | sort | python reducer.py > output.txt
```

### 4. 数据量考虑

- 训练集约 40MB+，行数百万级
- 本地测试可先用 `head -1000` 截取小样本
- 注意内存使用，避免在 Reducer 中加载所有数据

### 5. 实验报告要求

需要包含：
- **设计思路**：每个任务的 MapReduce 设计逻辑
- **运行结果**：截图 + 关键数据分析
- **数据分析**：从结果中得出的结论
- **改进方向**：性能优化、功能扩展等

---

## 📊 预期输出示例

### 任务一输出示例
```
1234_offline	150	200	80
1234_online	120	180	90
5678_offline	200	300	100
```

### 任务二输出示例
```
1234	0:50,1:80,2:60,null:20
5678	0:30,1:70,2:90,3:40
```

### 任务三输出示例
```
100001	2.5
100002	3.8
100003	5.2
```

---

## 🚀 下一步计划

1. ✅ 理解实验要求和数据结构
2. ⬜ 创建项目目录结构
3. ⬜ 实现任务一的 Mapper 和 Reducer
4. ⬜ 本地测试任务一
5. ⬜ 依次完成任务二、三、四
6. ⬜ 编写实验报告
7. ⬜ 整理代码和文档

---

## ❓ 需要您补充的信息

1. **运行环境**：
   - 是否有 Hadoop 集群环境？
   - 还是需要本地模拟运行？
   - Python 版本？

2. **具体要求**：
   - 任务二中"距离为 x 的消费者人数"是按距离分别输出，还是汇总在一行？
   - 是否需要可视化结果？
   - 实验报告格式有具体要求吗？

3. **时间安排**：
   - 实验截止时间？
   - 是否需要分阶段提交？

请告诉我这些信息以及其他补充要求，我将据此调整实现方案！
